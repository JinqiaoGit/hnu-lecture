{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Ticker Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = pd.read_csv('ticker.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_names = tickers['Symbol'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AAU'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_names[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Notionals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_float():\n",
    "    number = str(round(random.uniform(0, 1000), 3))\n",
    "    union = ['trillion', 't', 'billion', 'b', 'million', 'm', 'thousand', 'hundred', '']\n",
    "    number += union[random.choice(list(range(len(union))))]\n",
    "    return number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'658.65million'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解析语法\n",
    "def create_grammar(grammar_str, split = '=>', line_split = '\\n'):\n",
    "    grammar = {}\n",
    "    for line in grammar_str.split(line_split):\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        else:\n",
    "            exp, stmt = line.split(split)\n",
    "            grammar[exp.strip()] = [s.split() for s in stmt.split('|')]\n",
    "    return grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(gram, target):\n",
    "    if target not in gram:\n",
    "        return target    # means target is a terminal expression\n",
    "    # target in gram 意味着target是可以继续拓展下去的\n",
    "    else:\n",
    "        expaned = [generate(gram, t) for t in random.choice(gram[target])]\n",
    "        return ' '.join([e if e!='/n' else '\\n' for e in expaned if e != 'null'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "host1 = 'host = 寒暄 询问 业务相关 结尾|询问 业务相关| 业务相关 | 寒暄 业务相关\\n寒暄 = 打招呼 称谓 | 打招呼\\n称谓 = 人称 , | 人称\\n人称 = name\\n打招呼 = Hi | Hello | Dear | null\\n询问 = Can I | May I\\n业务相关 = 玩玩 具体业务 | 具体业务 玩玩 | 具体业务\\n玩玩 = Call | Put | Buy | Sell | buy | sell | call | put\\n具体业务 = 1234\\n结尾 = thx. | Thanks | Thank you. | null'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "fake = Faker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "samples = []\n",
    "for i in range(3000):\n",
    "    gram = create_grammar(host1, split = \"=\")\n",
    "    target = \"host\"\n",
    "    sample = generate(gram, target)\n",
    "    name = fake.name()\n",
    "    labels = []\n",
    "    if 'name' in sample:\n",
    "        sample = sample.replace('name', name)\n",
    "        labels.append(['NAME', re.search(name, sample).span()])\n",
    "    num = generate_float()\n",
    "    ticker = random.choice(ticker_names)\n",
    "    if '1234' in sample:\n",
    "        sample = sample.replace('1234', ' '.join([num, ticker]))\n",
    "        labels.append(['TICKER', re.search(ticker, sample).span()])\n",
    "        labels.append(['NOTIONAL', re.search(num, sample).span()])\n",
    "    samples.append({\n",
    "        \"text\": sample,\n",
    "        \"label\": labels\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(samples, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "training",
   "language": "python",
   "name": "training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
